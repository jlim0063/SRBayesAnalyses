---
title: "**NSF study Main Data Analyses**"
---

### Load libraries

```{r,echo=FALSE}

## Load Packages

## Data wrangling
library(dplyr)   
library(data.table)
library(tidyr)
library(readxl)      # required for read_excel() method
library(glue)



## Visualisation libraries
library(ggplot2)
library(ggpubr)
library(visreg)
library(ggsignif)    # For significance bars on ggplots
library(ggpubr)

library(egg)         # required for ggarrange (panelling multiple ggplots)

## Modelling
library(lme4)        # required for `Lmer() and glmer()` methods
library(lmerTest)    # required for p-value approximations

library(emmeans)     # required to retrieve least-square estimates, using `lsmeans()` and `emmeans`


library(aod)         # required to call model comparison methods, such as `AIC`, `BIC`
library(car)         # required for Chi-square test of Coefficient Equality `linearHypothesis`
library(MuMIn)       # required for r.squaredGLMM() function
library(performance) # required for check_collinearity function
library(sjPlot)      # required for `tab_model(model)`, which provides a formatted output of the model in APA style.

library(DHARMa)      # required for residual inspection

# Miscellaneous libraries not used
# library(piecewiseSEM)


# Turn off scientific notation
options(scipen = 20)

```

### Additional function definition

```{r}

# To retrieve standardised coefficients, if needed (not used)
lm.beta.lmer <- function(mod) {
   b <- fixef(mod)[-1]
   sd.x <- apply(getME(mod,"X")[,-1],2,sd)
   sd.y <- sd(getME(mod,"y"))
   b*sd.x/sd.y
}

```

------------------------------------------------------------------------

# Data Management Pt 1

```{r,echo=FALSE, results = "hide"}

# Read data
nsf.data <- as.data.table(read_excel("../data/exp1_NSF_study_data/data_master.xlsx"))

# Check for duplicates
nsf.data <- nsf.data[duplicated(nsf.data) == FALSE,]

# Convert Condition to factor
nsf.data$Condition <- factor(nsf.data$Condition,
                             levels = c("WR", "TSD", "SR"));
# Convert Session to factor variable
nsf.data$Session <- factor(nsf.data$Session,
                           levels = c(1, 2),
                           labels = c("1st", "2nd"));


```

# Data Management Pt 2

Inspecting the participant IDs show that there are some participants who did not complete both WR and their assigned conditions.

## Participant ID breakdown

```{r, echo=FALSE, results = "hide"}
# Get number of participants that have each respective sleep condition
wr_pts  <- unique(nsf.data[nsf.data$Condition == 'WR', ]$PtID)
tsd_pts <- unique(nsf.data[nsf.data$Condition == 'TSD', ]$PtID)
sr_pts  <- unique(nsf.data[nsf.data$Condition == 'SR', ]$PtID)


# Sort order
wr_pts  <- sort(wr_pts, decreasing = FALSE);
tsd_pts <- sort(tsd_pts, decreasing = FALSE);
sr_pt   <- sort(sr_pts, decreasing = FALSE);

# Print number of participants by condition
length(wr_pts); length(tsd_pts); length(sr_pts)

# Print total number of participants in whole dataset
length(unique(nsf.data$PtID))


setdiff(sr_pts, wr_pts)             # SR participants missing WR data
setdiff(tsd_pts, wr_pts)            # TSD participants missing WR data
setdiff(wr_pts, c(sr_pts, tsd_pts)) # Participants with WR trials data, but missing their respective sleep loss trials data

# need to look at 41 again
```

From inspection of eligibility data: - Data for #41 needs to be dropped completely due to not meeting age criteria. - The following data should be dropped due to idiosyncratic reasons for malperformance on task (e.g. fell asleep during task) - All trials for Participants 13, 22, 45 - TSD trials for Participant 15 - SR trials for Participant 22 - WR trials for Participant 58

```{r, echo = FALSE}

# Store all inegligible participant IDs in one array.
nsf.ineligible_pts <- c(13, 22, 41, 45)

```

## Extract & concatenate participant `KSS` data

```{r, echo=FALSE, results = "hide"}
nsf.temp.KSS <- read.csv("../data/exp1_NSF_study_data/KSS_data.csv")
nsf.temp.KSS <- nsf.temp.KSS[ , c("Subject", "Condition", 'KSS_wr', 'KSS_sl')];

# Create new KSS column in nsf.data
nsf.data$KSS <- NA;
pt_list      <-  unique(nsf.data$PtID);

# Loop through participant ids and extract KSS values from `nsf.kss.data`
for (id in pt_list){
  if(id %in% nsf.temp.KSS$Subject){
    KSS.WR <- nsf.temp.KSS[nsf.temp.KSS$Subject == id, ]$KSS_wr
    KSS.SL <- nsf.temp.KSS[nsf.temp.KSS$Subject == id, ]$KSS_sl
    nsf.data[nsf.data$PtID == id & nsf.data$Condition == "WR", ]$KSS             <- KSS.WR
    nsf.data[nsf.data$PtID == id & nsf.data$Condition %in% c("TSD", "SR"), ]$KSS <- KSS.SL
    print(glue("KSS data for Subject ID {id} added."))
  } else {
    print(glue("No KSS data for Subject ID {id} found."))
  }
}

# Remove placeholder variables from global
rm(pt_list); rm(nsf.temp.KSS)

```

## Extract & conctatenate sex data from original demographic data file, for participants that are missing sex data

```{r}

# Participants with missing demographic information
nsf.missing_sex <- unique(nsf.data[is.na(nsf.data$sex),]$PtID)
nsf.missing_age <- unique(nsf.data[is.na(nsf.data$age),]$PtID)
print(unique(c(nsf.missing_age, nsf.missing_sex)));


# View participants missing KSS data. 
a <- distinct(nsf.data, PtID, Condition,.keep_all = TRUE)
print(a[is.na(a$KSS)==TRUE, 2:3 ])
nsf.missing_kss <- a[is.na(a$KSS)==TRUE, 2:3 ]$PtID

# Add these participants to incomplete pt list
nsf.incomplete_pts <- unique(c(nsf.missing_age, nsf.missing_sex, nsf.missing_kss));

# Remove placeholder variables from global
rm(a)

```

------------------------------------------------------------------------

# Data Management Pt 3

## Fill in missing participant demographic data

These data were retrieved from the participant demographic file.

```{r}

# Fill in missing demographic data if available
nsf.data[nsf.data$PtID == 60, 'age'] <- 19 
nsf.data[nsf.data$PtID == 60, 'sex'] <- 'M'
nsf.data[nsf.data$PtID == 50, 'age'] <- 33 
nsf.data[nsf.data$PtID == 50, 'sex'] <- 'F'
nsf.data[nsf.data$PtID == 3, 'age']  <- 20
nsf.data[nsf.data$PtID == 3, 'sex']  <- 'F'
nsf.data[nsf.data$PtID == 61, 'age'] <- 19
nsf.data[nsf.data$PtID == 61, 'sex'] <- 'M'
nsf.data[nsf.data$PtID == 59, 'age'] <- 23
nsf.data[nsf.data$PtID == 59, 'sex'] <- 'M'
nsf.data[nsf.data$PtID == 41, 'age'] <- 44
nsf.data[nsf.data$PtID == 41, 'sex'] <- 'M'


```

## Drop ineligible participants

```{r, echo = FALSE}
nsf.data <- nsf.data[!(nsf.data$PtID == 22 & nsf.data$Condition == 'SR'), ]  # Drop Participant 22's SR trials**
nsf.data <- nsf.data[!(nsf.data$PtID == 15 & nsf.data$Condition == 'TSD'), ] # Drop Participant 15's TSD trials**
nsf.data <- nsf.data[!(nsf.data$PtID == 58 & nsf.data$Condition == 'WR'), ]  # Drop Participant 58's WR trials

# Drop all participants in ineligible list
nsf.data <- nsf.data[!nsf.data$PtID %in% nsf.ineligible_pts, ]

```

------------------------------------------------------------------------

# Analyses

## KSS model

```{r, echo = FALSE}

# Subset data such that each participant only has 1 KSS entry per condition
nsf.data.KSS <- distinct(nsf.data, PtID, Condition, .keep_all = TRUE)


```

```{r, echo = FALSE}


length(unique(nsf.data.KSS$PtID))
# Check KSS distribution
plot.nsf.KSS.hist   <- ggplot(nsf.data.KSS, aes(x = KSS)) + geom_density()

# Transformations (not used)
nsf.data.KSS$logKSS  <- log(nsf.data.KSS$KSS)
nsf.data.KSS$sqrtKSS <- sqrt(nsf.data.KSS$KSS)
plot.nsf.logKSS.hist <- hist(nsf.data.KSS$logKSS)

# Build the KSS modelconf
m.nsf.KSS <- lmer(KSS ~ 1 + Condition+ (1|PtID), nsf.data.KSS)

# View output
tab_model(m.nsf.KSS)

```

### Normality of Residuals check

```{r}

# Check residuals
sim_output <- simulateResiduals(m.nsf.KSS, plot = F); plotQQunif(sim_output);plotResiduals(sim_output)


```

### Plot KSS model

```{r, echo = FALSE}

nsf.data.KSS.lsmeans <- as_tibble(lsmeans(m.nsf.KSS, specs = "Condition")) %>% 
  slice(match(c("WR", "SR", "TSD"), Condition)) %>%                  # Rearrange such that order is WR, SR, TSD
  mutate(Condition = factor(Condition, levels = c("WR","SR","TSD"))) # Factorize condition such that ggplot follows custom order

# Define plot 

nsf.plot.KSS.lsmeans <- ggplot(nsf.data.KSS.lsmeans, aes(x = Condition, y = lsmean)) +
  geom_col(fill = c("#999DA0", "#777B7E", "#C7C6C1"), colour = "black", linewidth =1) +
  scale_y_continuous(limits = c(0, 8)) +
  labs(x = "Condition", y = "KSS score") + 
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), color = "#222021", width = 0.2, linewidth = 1)+
  theme_pubr() +
  #theme_classic() + 
  theme(aspect.ratio = .8, axis.title = element_text(size = 20),  axis.text = element_text(size = 20), axis.line = element_line(linewidth = 2)) 
  # geom_text(aes(label = round(lsmean, 2)), position = position_dodge(1), vjust = -5, size = 5.5)


# Save plot
ggsave(
  plot = nsf.plot.KSS.lsmeans,
  filename = "../img/nsf/nsf_KSS_score.png",
  bg = "transparent"
  )



# (Only run at end) combined plots
library(cowplot)
combined.plot.KSS.lsmeans <- plot_grid(nsf.plot.KSS.lsmeans, bds.plot.KSS.lsmeans)

ggsave(
  plot = combined.plot.KSS.lsmeans, 
  filename = "../img/combined_KSS_score.png",
  bg = "transparent"
)

```

## Accuracy model

```{r}
# Subset without noBrainers
nsf.data.exNB     <- nsf.data[nsf.data$NoBrainer == 0, ] # Remove ineligible trials


# Build accuracy model
m.nsf.ACC1 <- glmer(
  IsCorrect ~ 1 + Session + entropy + Condition + LogBaserate + LogLLA+ (1|PtID), 
  family = binomial('logit'),
  data = nsf.data.exNB
)

m.nsf.ACC2 <- glmer(
  IsCorrect ~ 1 + Session + entropy + LogBaserate LogLLA+ (1|PtID), 
  family = binomial('logit'),
  data = nsf.data.exNB
)


# Print model summary
summary(m.nsf.ACC1)
tab_model(m.nsf.ACC1)

```

### Plot accuracy model

```{r, echo = FALSE}

# Code to call least-square marginal means on response scale
nsf.data.ACC <- as_tibble(emmeans(m.nsf.ACC, spec = c( "Condition"), type = "response"))
nsf.data.ACC$Condition <- factor(nsf.data.ACC$Condition, levels = c("WR", "SR", "TSD"))


nsf.plot.ACC <- ggplot(nsf.data.ACC, aes(x = factor(Condition, levels = c("WR","SR","TSD")), y = prob)) + 
  geom_point(size = 3) +
  scale_y_continuous(limits = c(0.5, 1)) +
  labs(x = "Condition", y = "Probability of Accurate Response") +
  scale_color_manual(values = c("#202A44", "#9F1D35")) + 
  geom_errorbar(aes(ymin = nsf.data.ACC$asymp.LCL, ymax = nsf.data.ACC$asymp.UCL), color = '#595959', width = 0.1) + 
  theme_bw()+theme(aspect.ratio = 0.75, axis.title = element_text(size=18), axis.text=element_text(size=15)) ;


# Save plot
# ggsave(
#   plot = nsf.plot.ACC,
#   filename = "img/nsf/NSF_taskAccuracy.png",
#   bg = "transparent"
#   )



```

## Pooled probit model (Decision Weights)

```{r}

# View length of unique IDs
# length(unique(nsf.data.exNB[nsf.data.exNB$Condition == 'TSD',]$PtID))
# length(unique(nsf.data.exNB[nsf.data.exNB$Condition == 'SR', ]$PtID))
# length(unique(nsf.data.exNB[nsf.data.exNB$Condition == 'WR', ]$PtID))
# length(unique(nsf.data.exNB$PtID))


#Build pooled model that excludes NoBrainer trials
m.nsf.exNB <- glmer(PtResp ~ 1 + Condition*LogBaserate + Condition*LogLLA + 
                    (1  |PtID),             
                  family = binomial('probit'),
                  nsf.data.exNB);

# Print model summary
summary(m.nsf.exNB)

```

### Normality of Residuals check

```{r}
# Check residuals
sim_output <- simulateResiduals(m.nsf.exNB, plot = F); plotQQunif(sim_output);plotResiduals(sim_output)


```

### Plot Decision Weights

```{r, echo = FALSE}
nsf.data.DW <- tibble(.rows = 6)
nsf.data.DW$condition <-  c("WR", "WR", "TSD", "TSD", "SR", "SR")
nsf.data.DW$information <-  c(rep(c("Evidence", "Base Rate"), 3))


nsf.data.DW$ coefficients <- c(0.71187, 1.38736,
                                        (0.711873 - 0.02729), (1.387346 - 0.0147 ),
                                        (0.711873 - 0.15188), (1.387346 - 0.21893)
                                        )


nsf.data.DW$ci_lower <- c(0.6392888, 1.2548631,
                                   0.5613523, 1.1481704,
                                   0.4401318, 0.9502206);

nsf.data.DW$ci_upper <- c(0.7844538490, 1.5198590053,
                                   0.8078151152, 1.597176358,
                                   0.6798578593, 1.386698082);
  
nsf.data.DW$condition <- factor(nsf.data.DW$condition, levels = c("WR","SR","TSD"))
nsf.data.DW$information <- factor(nsf.data.DW$information, levels = c("Base Rate", "Evidence"))


plot.nsf.DW <- ggplot(data = nsf.data.DW, aes( x = condition, y = coefficients, shape = information)) + 
  geom_point(size=  3, aes(shape = information)) +                          
  scale_y_continuous(limits = c(0, 2)) +                                      # Sets y axis range      
  labs(x = "Condition", y = "Decision Weight", shape = "Information", title = "Experiment 1") +        # Changes labels (axis titles and legend title)
  
  scale_shape_manual(values = c(17, 19)) +
  # scale_color_manual(labels = c("Draw Outcome", "Base Rate Odds"), values = c("#696969", "#3E424B"))+
  
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), color = '#595959', width = 0.15, linewidth = 1)+ # Add error bars
  theme_bw(base_size = 15) + theme(aspect.ratio =  1.8, axis.title = element_text(size = 15), axis.text = element_text(size = 15), panel.border = element_rect(linewidth = 2))  

# Save as png with transparent background
ggsave(plot = plot.nsf.DW,
       filename = "../img/nsf/NSF_decisionWeights.png",
       bg = "transparent");




```

------------------------------------------------------------------------

# RT Analyses

```{r, echo = FALSE}

# Convert RT to numeric
nsf.data.exNB$RT <- as.numeric(nsf.data.exNB$RT)

# Create LogBaserate and LogLLA strength by factorising/taking absolute values
nsf.data.exNB[,LLAstrength:=factor(abs(LogLLA), levels = c(0, 1.38629436111989, 2.77258872223978, 4.15888308335967), labels = c("none", "low", "mid", "high"))]
nsf.data.exNB[,LBRstrength:=factor(abs(LogBaserate), levels = c(0, 0.693147180559947, 1.6094379124341), labels = c("low", "mid", "high"))]

# Create logRT variable3
nsf.data.exNB.rt <- nsf.data.exNB[RT>0]
nsf.data.exNB.rt[,logRT:=log(RT)]

# Create z score for log RT
z_score <- function(x){
  z <- (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  return(z)
}

nsf.data.exNB.rt[,logRT_zscore:=z_score(logRT)]

# Build model with log transformation of RT
m.nsf.rt <- lmer(logRT~ 1 + Condition*LBRstrength + Condition*LLAstrength + (1|PtID), data = nsf.data.exNB.rt[logRT_zscore>-3.29])

# drop interactions as all n.s.
m.nsf.rt <- lmer(logRT ~ 1 + Condition + LBRstrength + LLAstrength + (1 |PtID), data = nsf.data.exNB.rt[logRT_zscore > -3.29])

```

Stronger base rate and likelihood information seems to result in longer RTs, which is surprising. Could it be due to amount of uncertainty?

```{r}

# Formula for shannon entropy
calc_entropy <- function(prob_vector) {
  # Check if the input is a vector of length 2
  if ( length(prob_vector) != 2) {
    stop("Input must be a vector of length 2 containing probability values.")
  }
  
  # Check if the probabilities sum up to 1
  if (abs(sum(prob_vector) - 1) > 1e-8) {
    stop("Probabilities must sum up to 1.")
  }
  
  # Calculate Shannon's entropy
  H <- -sum(prob_vector * log2(prob_vector))
  return(H)
}

# Calculate shannon's entropy 

nsf.data.exNB$entropy <- 0
for (row_x in 1:nrow(nsf.data.exNB)){
  prob1 <- nsf.data.exNB[row_x, PosteriorProb]
  prob2 <- 1-prob1
  nsf.data.exNB[row_x, "entropy"] <- calc_entropy(c(prob1, prob2))
}

# include entropy main effect
m.nsf.rt <- lmer(RT ~ 1 + Condition + entropy + LBRstrength + LLAstrength + (1 + LBRstrength |PtID), 
                 data = nsf.data.exNB.rt[logRT_zscore > -3.29 ])
m.nsf.rt2 <- lmer(logRT ~ 1 + Condition + entropy + LBRstrength + LLAstrength + (1|PtID), 
                 data = nsf.data.exNB.rt[logRT_zscore > -3.29 & LLAstrength != "high"])


```

Weird that high LBR strength = longer reaction times. Running a model below that looks at the effect of no blk balls on the logRT, for only trials with *high* LBR strength. Results show that when NoBlkBall = 5, participants talke significantly longer to make decision. 

``` {r}

# Get distribution of high  LBRstrength trials according to no. black balls
table(nsf.data.exNB.rt[logRT_zscore > -3.29 & LBRstrength == "high"]$NoBlkBall)/nrow(nsf.data.exNB.rt[logRT_zscore > -3.29 & LBRstrength == "high"])*100
table(nsf.data.exNB.rt[logRT_zscore > -3.29 & LBRstrength == "high"]$NoBlkBall)

m.nsf.bb <- lmer(logRT ~  1 + factor(NoBlkBall) + (1|PtID), data = nsf.data.exNB.rt[logRT_zscore > -3.29 & LBRstrength == "high"])
m.nsf.bb2 <- lmer(logRT ~ 1 + factor(NoBlkBall) + (1|PtID), data = nsf.data.exNB.rt[logRT_zscore>-3.29 & LogBaserate == min(LogBaserate)])
m.nsf.bb3 <- lmer(logRT ~ 1 + factor(NoBlkBall) + (1|PtID), data = nsf.data.exNB.rt[logRT_zscore>-3.29 & round(LogBaserate,2) ==  0.69])

summary(m.nsf.bb3)

# It turns out that trials with 5/6 or 1/6 are always paired with NoBlkBalls that suggest the opposite information. Call the two tables below to check the distribution of NoBlkBalls on trials with max or min LogBaserate. 
table(nsf.data.exNB.rt[logRT_zscore>-3.29 & LogBaserate == max(LogBaserate)]$NoBlkBall)
table(nsf.data.exNB.rt[logRT_zscore>-3.29 & LogBaserate == min(LogBaserate)]$NoBlkBall)

# This is the same for trials with 2/6 or 4/6 odds
table(nsf.data.exNB.rt[logRT_zscore>-3.29 & round(LogBaserate,2) == .69]$NoBlkBall)
table(nsf.data.exNB.rt[logRT_zscore>-3.29 & round(LogBaserate,2) == -.69]$NoBlkBall)

```


---

# Test

```{r}
nsf.data <- as.data.table(nsf.data)
nsf.data[,LBRstrength:=abs(LogBaserate)]
nsf.data[,LLAstrength:=abs(LogLLA)]
nsf.copy <- copy(nsf.data)
nsf.copy <- nsf.copy[RT!=0]
nsf.copy[,logRT := log(as.numeric(RT))]

nsf.copy$entropy <- 0
for (row_x in 1:nrow(nsf.copy)){
  prob1 <- nsf.copy[row_x, PosteriorProb]
  prob2 <- 1-prob1
  nsf.copy[row_x, "entropy"] <- calc_entropy(c(prob1, prob2))
}


test.rt <-lmer(logRT ~ 1 + poly(LBRstrength,2) + LLAstrength + Condition + entropy + (1 |PtID), data = nsf.copy)


# ggplot(nsf.copy, aes(x=RT, fill=as.factor(LBRstrength))) + geom_boxplot() + theme_pubr() 


```

```{r}
plot.nsf.LLAs <- ggplot(data = nsf.data.exNB.rt, aes(x = LLAstrength, fill = LLAstrength)) + 
  geom_bar() + facet_grid(.~ LBRstrength) + theme_pubr()

plot.nsf.LBRs <- ggplot(data = nsf.data.exNB.rt, aes(x = LBRstrength, fill = LBRstrength)) +
  geom_bar(color = "black") + facet_grid(.~LLAstrength) + theme_pubr() 

plot.nsf.rt.bxp1 <- ggplot(nsf.data.exNB.rt[logRT_zscore>-3.29], aes(x = Condition, y = logRT, group = Condition)) +
  geom_boxplot(aes(fill=Condition)) + geom_point(position = position_jitter(width = 0.1)) + facet_grid(.~ LBRstrength)

plot.nsf.rt.bxp2 <- ggplot(nsf.data.exNB.rt[logRT_zscore>-3.29], aes(x=LBRstrength, y = logRT, group = LBRstrength)) +
  geom_boxplot(aes(fill = LBRstrength)) + facet_grid(.~ Condition) + theme_pubr()

plot.nsf.rt.full <- ggplot(nsf.copy[z_score(logRT)>-3.29], aes(x=LBRstrength, y = logRT, group = LBRstrength)) +
  geom_boxplot(aes(fill = LBRstrength)) + facet_grid(.~ Condition) +theme_pubr()


nsf.copy[,LBRstrength:=factor(LBRstrength, levels=sort(unique(LBRstrength)), labels = c(1, 2, 3, 4, 5))]

# plot.nsf.rt.bxp1 <- ggplot(nsf.copy, aes(x = LBRstrength, y = RT, group = LBRstrength)) +
#   geom_boxplot(aes(fill=LBRstrength))  + theme_pubr()
  # facet_grid(.~ Condition) 
  # geom_point(position = position_jitter(width = 0.1))


```

END
