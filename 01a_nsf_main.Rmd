---
title: "**NSF study Main Data Analyses**"
output: html_notebook
---

## Load libraries

```{r,echo=FALSE}

## Load Packages

library(dplyr)
library(readxl)
library(tidyr)
library(glue)


# Visualisation libraries
library(ggplot2)
library(ggsignif) # For significance bars on ggplots
library(visreg)

library(egg) # for ggarrange (panelling multiple ggplots)
library(lme4)
library(lmerTest)
library(brms)
library(emmeans)

library(aod)
library(car)   # For Chi-square test of Coefficient Equality `linearHypothesis`
library(MuMIn)
library(performance) # for check_collinearity function
library(sjPlot) # This gives a summary output of the model in APA style. Use `tab_model(model)`


library(piecewiseSEM)
library(DHARMa)


# Turn off scientific notation
options(scipen = 20)

```

# Data Management

```{r,echo=FALSE}

# Read data
nsf.data <- read_excel("./data/NSF_study_data/data_master.xlsx")


# Check for duplicates
nsf.data <- distinct(nsf.data)

nsf.data<- nsf.data[duplicated(nsf.data) == FALSE,]

# Check variable names 
names(nsf.data)


```

## Factorize and label Condition and Session

```{r,echo=FALSE}
# Convert Condition to factor
typeof(nsf.data$Condition);
nsf.data$Condition <- factor(nsf.data$Condition,
                             levels = c("WR", "TSD", "SR"));

# Convert Session to factor variable
nsf.data$Session <- factor(nsf.data$Session,
                           levels = c(1, 2),
                           labels = c("1st", "2nd"));
                     

# Create a subset with just SR and WR data, for now. 
nsf.data.sr <- subset(nsf.data, Condition != 'TSD')


```

------------------------------------------------------------------------

# Data management

## Participant ID breakdown

```{r, echo=FALSE}
# Get number of participants who have WR data
wr_pts <- unique(nsf.data[nsf.data$Condition == 'WR', ]$PtID)
length(wr_pts)

# Get number of participants with TSD data
tsd_pts <- unique(nsf.data[nsf.data$Condition == 'TSD', ]$PtID)

# Get number of participants with SR data
sr_pts <- unique(nsf.data[nsf.data$Condition == 'SR', ]$PtID)


# Sort order
wr_pts <- sort(wr_pts, decreasing = FALSE);
tsd_pts <- sort(tsd_pts, decreasing = FALSE);
sr_pts <- sort(sr_pts, decreasing = FALSE);

# Print number of participants by condition
length(wr_pts); length(tsd_pts); length(sr_pts)
# Print total number of participants in whole dataset
length(unique(nsf.data$PtID))

# SR participants missing WR data
setdiff(sr_pts, wr_pts)
# TSD participants missing WR data
setdiff(tsd_pts, wr_pts)
# Participants with WR trials data, but missing their respective sleep loss trials data
setdiff(wr_pts, c(sr_pts, tsd_pts)) # need to look at 41 again
```

From Sean:
For the demographics (41, 50, 59, 60, 61), I can confirm all those people dropped out of the study or were withdrawn. Same with subj 03. Attached is an excel file with what I think is the full set of demographics (in Consented tab). There is also a "Dropped_Withdrawn" tab that has reasons for not completing. Most are legit, but note **subject 41 lied about his age**. He was actually outside our age range, so **should be dropped entirely**. The others I think you can keep the data you have.

Participants that David dropped: 13, 15, 22, 45, 58
Participants that should be dropped completely: 41. **should I drop 3 as well as Demographics record indicate noncompliance?**


```{r, echo = FALSE}
# Store all the participants missing either condition in one array
ineligible_pts <- c(setdiff(sr_pts, wr_pts),setdiff(tsd_pts, wr_pts),setdiff(wr_pts, c(sr_pts, tsd_pts)) )

ineligible_pts <- c(ineligible_pts, c(13, 15, 22, 45)) # Add participants that David dropped
ineligible_pts <- ineligible_pts[!ineligible_pts %in% c(3, 50,59,60,61)] # Re-add 50, 59, 60, 61 as their WR data is useful.
ineligible_pts

```

## Extract & concatenate participant `KSS` data

```{r, echo=FALSE}
nsf.kss.data <- read.csv("./data/NSF_study_data/KSS_data.csv");
nsf.kss.data <- nsf.kss.data[ , c("Subject", "Condition", 'KSS_wr', 'KSS_sl')];

# Create new KSS column in nsf.data
nsf.data$KSS = NA;
pt_list <-  unique(nsf.data$PtID);

# Loop through participant ids and extract KSS values from `nsf.kss.data`
for (id in pt_list){
  if(id %in% nsf.kss.data$Subject){
    KSS.WR <- nsf.kss.data[nsf.kss.data$Subject == id, ]$KSS_wr
    KSS.SL <- nsf.kss.data[nsf.kss.data$Subject == id, ]$KSS_sl
    nsf.data[nsf.data$PtID == id & nsf.data$Condition == "WR", ]$KSS <- KSS.WR
    nsf.data[nsf.data$PtID == id & nsf.data$Condition %in% c("TSD", "SR"), ]$KSS <- KSS.SL
    print(glue("KSS data for Subject ID {id} added."))
  } else {
    print(glue("No KSS data for Subject ID {id} found."))
  }
}


```

### View participants missing demographic/KSS information

```{r}

# Participants with missing demographic information
pt_missingdemo <- unique(nsf.data[is.na(nsf.data$sex),]$PtID)
print(pt_missingdemo);

# View participants missing KSS data. 
a <- distinct(nsf.data, PtID, Condition,.keep_all = TRUE)
print(a[is.na(a$KSS)==TRUE, 2:3 ]); pt_missing_kss <- a[is.na(a$KSS)==TRUE, 2:3 ]$PtID

# Add these participants to incomplete pt list
nsf_incomplete_pts <- c(nsf_incomplete_pts, pt_missing_kss)

```

---

# Analyses

## Drop ineligible participants

```{r}

# Can use WR data, not SD for 15, 22
# Can use SD for 58, not WR
ineligible_pts <- unique(ineligible_pts) # make sure there's no duplicates

print(ineligible_pts)
ineligible_pts

# Fill in missing demographic data if available
nsf.data[nsf.data$PtID == 60, 'age'] <- 19 
nsf.data[nsf.data$PtID == 60, 'sex'] <- 'M'
nsf.data[nsf.data$PtID == 50, 'age'] <- 33 
nsf.data[nsf.data$PtID == 50, 'sex'] <- 'F'
nsf.data[nsf.data$PtID == 3, 'age'] <- 20
nsf.data[nsf.data$PtID == 3, 'sex'] <- 'F'
nsf.data[nsf.data$PtID == 61, 'age'] <- 19
nsf.data[nsf.data$PtID == 61, 'sex'] <- 'M'
nsf.data[nsf.data$PtID == 59, 'age'] <- 23
nsf.data[nsf.data$PtID == 59, 'sex'] <- 'M'
nsf.data[nsf.data$PtID == 41, 'age'] <- 44
nsf.data[nsf.data$PtID == 41, 'sex'] <- 'M'


```

## KSS model

```{r, echo = FALSE}
# Subset data such that each participant only has 1 KSS entry per condition
nsf.data.kss <- distinct(nsf.data, PtID, Condition, .keep_all = TRUE)
nsf.data.kss <- nsf.data.kss[!nsf.data.kss$PtID %in% ineligible_pts,]                       # Remove ineligible participants
nsf.data.kss <- nsf.data.kss[!(nsf.data.kss$PtID == 58 & nsf.data.kss$Condition == 'WR'), ] # Remove participant 58's WR run



nsf.data.kss

```

```{r, echo = FALSE}
length(unique(nsf.data.kss$PtID))
# Check KSS distribution
hist(nsf.data.kss$KSS)

nsf.data.kss$sex
# Log transform KSS
nsf.data.kss$logKSS <- log(nsf.data.kss$KSS)

# Build the KSS model
m.nsf_KSS <- lmer(logKSS ~ 1 + Condition+ (1|PtID), nsf.data.kss)

 
# View output
summary(m.nsf_KSS)
tab_model(m.nsf_KSS)
```

## Accuracy model
```{r, echo = FALSE}
# Subset without noBrainers


nsf.data.b     <- nsf.data[nsf.data$NoBrainer == 0 & !nsf.data$PtID %in% ineligible_pts, ] # Remove ineligible pts
nsf.data.b     <- nsf.data.b[!(nsf.data.b$PtID == 58 & nsf.data.b$Condition == 'WR'), ]    # Remove participant 58's WR run

# Build accuracy model
m.accuracy.nsf <- glmer(
  IsCorrect ~ 1 + Condition + (1|PtID), 
  family = binomial('logit'),
  data = nsf.data.b
)

# Code to call least-square marginal means on response scale
emmeans(m.accuracy.nsf, specs = "Condition", type = "response")
  

```


## Pooled probit model

```{r}


length(unique(nsf.data.b[nsf.data.b$Condition == 'TSD',]$PtID))
length(unique(nsf.data.b[nsf.data.b$Condition == 'SR',]$PtID))
length(unique(nsf.data.b[nsf.data.b$Condition == 'WR', ]$PtID))
length(unique(nsf.data.b$PtID))

nsf.data.b

#Build pooled model that excludes NoBrainer trials
m.pool.b <- glmer(PtResp ~ 1 + Session + Condition*LogBaserate + Condition*LogLLA + 
                    (1  |PtID),             
                  family = binomial('probit'),
                  # control = glmerControl(boundary.tol = 1e10),
                  nsf.data.b);


sum(fixef(m.pool.b))
pnorm(1.998168)

pnorm(fixef(m.pool.b)[1] + fixef(m.pool.b)['LogBaserate'] + fixef(m.pool.b)['ConditionSR:LogBaserate'] ) #- pnorm(fixef(m.pool.b)[1])
pnorm(fixef(m.pool.b))

fixef(m.pool.b)

tab_model(m.pool.b)


```
### Chi-square test of coefficients
```{r, echo = false}
# Chi-square tests
linearHypothesis(m.pool.b, c(" LogBaserate =  LogLLA"), rhs=NULL,
                 vcov.=NULL, singular.ok=FALSE, verbose=FALSE)

linearHypothesis(m.pool.b, c("ConditionSR:LogBaserate =  ConditionSR:LogLLA"), rhs=NULL,
                 vcov.=NULL, singular.ok=FALSE, verbose=FALSE)

linearHypothesis(m.pool.b, c("ConditionTSD:LogBaserate =  ConditionTSD:LogLLA"), rhs=NULL,
                 vcov.=NULL, singular.ok=FALSE, verbose=FALSE)

```

### Plot Decision Weights

```{r, echo = FALSE}

decision_weights.nsf <- tibble(.rows = 6)
decision_weights.nsf$condition <-  c("WR", "WR", "TSD", "TSD", "SR", "SR")
decision_weights.nsf$information <-  c(rep(c("LogLLA", "LogBR"), 3))


decision_weights.nsf$ coefficients <- c(0.70921, 1.39835,
                                        (0.70921-0.02467), (1.39835-0.02575),
                                        (0.70921-0.14925), (1.39835-0.22994)
                                        )


decision_weights.nsf$ci_lower <- c(0.63565657 ,1.2636121,
                                   0.5607272, 1.14676528,
                                   0.43950169, 0.94879948);

decision_weights.nsf$ci_upper <- c(0.78277114, 1.53308538,
                                   0.80834525, 1.59842865,
                                   0.68041551, 1.38801353);
  
decision_weights.nsf$condition <- factor(decision_weights.nsf$condition, levels = c("WR","TSD","SR"))
decision_weights.nsf$information <- factor(decision_weights.nsf$information, levels = c("LogLLA", "LogBR"))


dw_plot.nsf <- ggplot(data = decision_weights.nsf, aes( x = condition, y = coefficients , color =  information)) + 
  geom_point(size=  2.5) + 
  scale_y_continuous(limits = c(0, 2)) +
  
  labs(title = "Decision Weights by Condition", x = "Condition", y = "Weight", color = "Information")+
  scale_color_manual(labels = c("Log Likelihood", "Log Prior Odds"), values = c("blue", "red"))+
  
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), color = '#595959', width = 0.1)+ # Add error bars
  theme_bw(base_size = 15) + theme(aspect.ratio =  2, axis.title = element_text(size = 16, face = "bold"))  


ggsave(plot = dw_plot.nsf,
       filename = "decision_weights_NSF.png",
       bg = "transparent");



```

### Plot Relative Decision Weights
```{r, echo = false}



# Calculate relative decision-weights

LogLLA      <-0.70921
LogBaserate <-1.39835


calculate_relative_dw = function(LogLLA, LogBaserate){
    rdw = (LogLLA-LogBaserate)/(LogLLA + LogBaserate);
    return(rdw)
};


WR_RDW.nsf  <- calculate_relative_dw(LogLLA, LogBaserate);
TSD_RDW.nsf <- calculate_relative_dw(LogLLA - .02467, LogBaserate - .02575)
SR_RDW.nsf  <- calculate_relative_dw(LogLLA - .14925, LogBaserate - .22994)

RDW.nsf <- tibble(.rows = 3);
RDW.nsf$condition <- c("WR", "TSD", "SR");
RDW.nsf$condition = factor(RDW.nsf$condition, levels = c("WR", "TSD", "SR"))
RDW.nsf$RDW <- c(WR_RDW.nsf, TSD_RDW.nsf, SR_RDW.nsf);

RDW_plot.nsf <- ggplot(data = RDW.nsf, aes(x = condition, y = RDW))+
  geom_bar(
    stat = 'identity',
    width = 0.5, fill = c("#202A44", "#4E4187", "#9B2915")
  )+
  xlab("Condition") + ylab("") +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  scale_y_continuous(limits = c(-1, 1)) +
  ggtitle(" ") +
  geom_text(aes(label = round(RDW, 2)), nudge_y = -0.04) + #Add text value on each bar
  theme_bw() + theme(aspect.ratio = 2, axis.text = element_text(size = 14), axis.title = element_text(size = 16, face = "bold"), plot.title = element_text(size = 18)) 
  
  
# Save as png with transparent background
ggsave( plot = RDW_plot.nsf,
        filename = "rel_decision_weights_NSF.png",
        bg = "transparent")



```


#### Normality of Residuals check
```{r}
# Check residuals
sim_output <- simulateResiduals(m.pool.b, plot = F)

plotQQunif(sim_output)
plotResiduals(sim_output)
```


## SR Weight Analyses

```{r, echo = FALSE}
# Subset noBrainer trials from just the SR participants
nsf.data.b.sr <- nsf.data.b[nsf.data.b$Condition=='WR'|nsf.data.b$Condition=='SR',]

# Build SR model, without the NoBrainers
m.SR.b <- glmer(PtResp ~  1 + Condition*LogBaserate + Condition*LogLLA + (1 |PtID), 
                family = binomial('probit'),
                data = nsf.data.b.sr);
  
# View output
summary(m.SR.b)
tab_model(m.SR.b)

# Check residuals
sim_output <- simulateResiduals(m.SR.b, plot = F)
plotQQunif(sim_output)
plotResiduals(sim_output)


```

## TSD weight Analyses

```{r, echo = FALSE}

# Subset noBrainer trials from just the TSD participants
nsf.data.b.tsd <- nsf.data.b[nsf.data.b$Condition=='WR'|nsf.data.b$Condition=='TSD',]

# Inspect number of pts that completed WR and TSD
sort(unique(nsf.data.b.tsd[nsf.data.b.tsd$Condition == 'WR', ]$PtID));sort(unique(nsf.data.b.tsd[nsf.data.b.tsd$Condition == 'TSD', ]$PtID))


# Build TSD model, without the NoBrainers (SINGULAR FIT ISSUE)
m.TSD.b <- lmer(PtResp~ 1 + Condition*LogBaserate + Condition*LogLLA + (1|PtID), nsf.data.b.tsd)

# View output
summary(m.TSD) 
summary(m.TSD.b)

summary(m.TSD.b)
tab_model(m.TSD.b)

```